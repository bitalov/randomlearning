{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f8361a2f421a4b3aad302dca0571911b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f106d6f7c7944c7fa2b5d7382468c3f7",
              "IPY_MODEL_7be5d1d9a5e241d989d18232cd24eaf8",
              "IPY_MODEL_175b9b6d8b6f4cc98c33dd3e7cdc90e4"
            ],
            "layout": "IPY_MODEL_d0d2a06be82c458b9d8e8f5286ff90fa"
          }
        },
        "f106d6f7c7944c7fa2b5d7382468c3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_accc2e608fed4962b267855453957683",
            "placeholder": "​",
            "style": "IPY_MODEL_fe08b084a27e4be6a77de0c03f4f9805",
            "value": "README.md: 100%"
          }
        },
        "7be5d1d9a5e241d989d18232cd24eaf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6926d5458c74928a8cdd12549cc58fb",
            "max": 2009,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_707cb18c710a4c9fb0cc1ecb97cf15b8",
            "value": 2009
          }
        },
        "175b9b6d8b6f4cc98c33dd3e7cdc90e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f1e3cb7cfb840e3927a166dd0372718",
            "placeholder": "​",
            "style": "IPY_MODEL_1846d5b0b44844b190220e9d97b31e97",
            "value": " 2.01k/2.01k [00:00&lt;00:00, 131kB/s]"
          }
        },
        "d0d2a06be82c458b9d8e8f5286ff90fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "accc2e608fed4962b267855453957683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe08b084a27e4be6a77de0c03f4f9805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6926d5458c74928a8cdd12549cc58fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "707cb18c710a4c9fb0cc1ecb97cf15b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f1e3cb7cfb840e3927a166dd0372718": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1846d5b0b44844b190220e9d97b31e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfb6139dd8d94f2684fa631348886f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00d15dad228a4b14b1477b4f97403ef4",
              "IPY_MODEL_dc1ce88e769b45a5ad6a5fe4df2f5508",
              "IPY_MODEL_4d9b679212704403a632b169082b8640"
            ],
            "layout": "IPY_MODEL_228a5e6e6e344f5f8402e0ca4a28c10c"
          }
        },
        "00d15dad228a4b14b1477b4f97403ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9011a8fb7004a76b3ab60a6ee7dbdc0",
            "placeholder": "​",
            "style": "IPY_MODEL_d560204e03ea497e8d24d3c6de12b981",
            "value": "poems.csv: 100%"
          }
        },
        "dc1ce88e769b45a5ad6a5fe4df2f5508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_728e2b406db848538d98c86de7690999",
            "max": 27306244,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b44874b67dac4b9091b87fc49557587d",
            "value": 27306244
          }
        },
        "4d9b679212704403a632b169082b8640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95893258ba244be6aadbae08fcf66727",
            "placeholder": "​",
            "style": "IPY_MODEL_b2e7e715e460433caf8d52dc3b6fd5a6",
            "value": " 27.3M/27.3M [00:00&lt;00:00, 41.3MB/s]"
          }
        },
        "228a5e6e6e344f5f8402e0ca4a28c10c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9011a8fb7004a76b3ab60a6ee7dbdc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d560204e03ea497e8d24d3c6de12b981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "728e2b406db848538d98c86de7690999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b44874b67dac4b9091b87fc49557587d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95893258ba244be6aadbae08fcf66727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2e7e715e460433caf8d52dc3b6fd5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02713cf125f3408cbb13cb82004bc155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1d8afb1c7214706a17d1a257098cff7",
              "IPY_MODEL_f6ebcdedf4794bbba5c5f48e898dba06",
              "IPY_MODEL_76bb7155af5644f784e8552c44fa9502"
            ],
            "layout": "IPY_MODEL_3b912907b7a8479dbe9cc737c8e2728c"
          }
        },
        "e1d8afb1c7214706a17d1a257098cff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1785d7d65c534dc1b5792ca6c20acb04",
            "placeholder": "​",
            "style": "IPY_MODEL_cc7a0f51773242fcaaccec3ef91671ae",
            "value": "Generating train split: 100%"
          }
        },
        "f6ebcdedf4794bbba5c5f48e898dba06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8659ea5c0924d74bad18d8350ddeb14",
            "max": 8875,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18bf43fd93d144e7adbeced23a4e3eda",
            "value": 8875
          }
        },
        "76bb7155af5644f784e8552c44fa9502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_234ad310f96a4138be92d385ac82f2c8",
            "placeholder": "​",
            "style": "IPY_MODEL_cee34b097a8a4e75a1e99a630821e087",
            "value": " 8875/8875 [00:00&lt;00:00, 18959.53 examples/s]"
          }
        },
        "3b912907b7a8479dbe9cc737c8e2728c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1785d7d65c534dc1b5792ca6c20acb04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc7a0f51773242fcaaccec3ef91671ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8659ea5c0924d74bad18d8350ddeb14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18bf43fd93d144e7adbeced23a4e3eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "234ad310f96a4138be92d385ac82f2c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cee34b097a8a4e75a1e99a630821e087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYwL4VLKUUV4",
        "outputId": "4ab786cd-d2d0-4f8d-9252-bd9c316776bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-27 07:32:28--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-01-27 07:32:28 (27.5 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGHfeV6xmRJ5",
        "outputId": "c4d0e5fc-2b53-444c-a7ab-b4f4daedb98d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "dataset = load_dataset(\"alwalid54321/Arabic_Poems\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f8361a2f421a4b3aad302dca0571911b",
            "f106d6f7c7944c7fa2b5d7382468c3f7",
            "7be5d1d9a5e241d989d18232cd24eaf8",
            "175b9b6d8b6f4cc98c33dd3e7cdc90e4",
            "d0d2a06be82c458b9d8e8f5286ff90fa",
            "accc2e608fed4962b267855453957683",
            "fe08b084a27e4be6a77de0c03f4f9805",
            "f6926d5458c74928a8cdd12549cc58fb",
            "707cb18c710a4c9fb0cc1ecb97cf15b8",
            "0f1e3cb7cfb840e3927a166dd0372718",
            "1846d5b0b44844b190220e9d97b31e97",
            "cfb6139dd8d94f2684fa631348886f6f",
            "00d15dad228a4b14b1477b4f97403ef4",
            "dc1ce88e769b45a5ad6a5fe4df2f5508",
            "4d9b679212704403a632b169082b8640",
            "228a5e6e6e344f5f8402e0ca4a28c10c",
            "c9011a8fb7004a76b3ab60a6ee7dbdc0",
            "d560204e03ea497e8d24d3c6de12b981",
            "728e2b406db848538d98c86de7690999",
            "b44874b67dac4b9091b87fc49557587d",
            "95893258ba244be6aadbae08fcf66727",
            "b2e7e715e460433caf8d52dc3b6fd5a6",
            "02713cf125f3408cbb13cb82004bc155",
            "e1d8afb1c7214706a17d1a257098cff7",
            "f6ebcdedf4794bbba5c5f48e898dba06",
            "76bb7155af5644f784e8552c44fa9502",
            "3b912907b7a8479dbe9cc737c8e2728c",
            "1785d7d65c534dc1b5792ca6c20acb04",
            "cc7a0f51773242fcaaccec3ef91671ae",
            "d8659ea5c0924d74bad18d8350ddeb14",
            "18bf43fd93d144e7adbeced23a4e3eda",
            "234ad310f96a4138be92d385ac82f2c8",
            "cee34b097a8a4e75a1e99a630821e087"
          ]
        },
        "id": "E3Zd5XY0nSg6",
        "outputId": "71a3b2e8-12bc-4a21-8659-786d97e7c02d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/2.01k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8361a2f421a4b3aad302dca0571911b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "poems.csv:   0%|          | 0.00/27.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfb6139dd8d94f2684fa631348886f6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/8875 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02713cf125f3408cbb13cb82004bc155"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of Authors:\n",
            "1. عبد القادر الجزائري\n",
            "2. الهدم بن امرئ القيس\n",
            "3. عبدالله البردوني\n",
            "4. الراضي بالله\n",
            "5. عبد الرحمن بن مساعد\n",
            "6. العباس بن الأحنف\n",
            "7. المثلم الفزاري\n",
            "8. هشام الجخ\n",
            "9. ابن الرعلاء\n",
            "10. يوسف النبهاني\n",
            "11. الوأواء الدمشقي\n",
            "12. محمد ولد ابن ولد أحميدا\n",
            "13. مصطفى صادق الرافعي\n",
            "14. الباخرزي\n",
            "15. حفني ناصف\n",
            "16. حافظ ابراهيم\n",
            "17. الإمام الشافعي\n",
            "18. الجاحظ\n",
            "19. العقار بن سليل\n",
            "20. فهد العسكر\n",
            "21. سهام آل براهمي\n",
            "22. الأصمعي\n",
            "23. زياد السعودي\n",
            "24. ابن دريد الأزدي\n",
            "25. عنترة بن شداد\n",
            "26. بغثر بن لقيط الأسدي\n",
            "27. النابغة الغنوي\n",
            "28. كريم معتوق\n",
            "29. أبو الهدى الصيادي\n",
            "30. الامير منجك باشا\n",
            "31. ابن حيوس\n",
            "32. الشريف الرضي\n",
            "33. إبراهيم اليازجي\n",
            "34. الأبيوردي\n",
            "35. لسان الدين بن الخطيب\n",
            "36. عبد الولي الشميرى\n",
            "37. مدثر بن إبراهيم بن الحجاز\n",
            "38. سليم عبدالقادر\n",
            "39. أم الضحاك المحاربية\n",
            "40. الميكالي\n",
            "41. نسيب عريضة\n",
            "42. عدنان الصائغ\n",
            "43. صردر\n",
            "44. إبراهيم عبد القادر المازني\n",
            "45. محمد المعولي\n",
            "46. أبو الفضل الكناني\n",
            "47. ظافر الحداد\n",
            "48. صخر الغي\n",
            "49. جورج جرداق\n",
            "50. ماء العينين\n",
            "51. الحارث بن حلزة\n",
            "52. جبلة بن الحارث\n",
            "53. ابن المُقري\n",
            "54. الأحنف العكبري\n",
            "55. دريد بن الصمة\n",
            "56. ابن الزقاق\n",
            "57. جابر المرني\n",
            "58. مصطفى التل\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 2: Extract unique author names\n",
        "author_names = set(poem['poet_name'] for poem in dataset['train'])\n",
        "\n",
        "# Step 3: Print all authors\n",
        "print(\"List of Authors:\")\n",
        "for idx, author in enumerate(author_names, 1):\n",
        "    print(f\"{idx}. {author}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxiBRVHXnfhy",
        "outputId": "d373de39-bd01-4afa-acd7-b893826c14aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['Unnamed: 0', 'poem_title', 'poem_meter', 'poem_verses', 'poem_theme', 'poet_name', 'poet_description', 'poet_era'],\n",
            "    num_rows: 8875\n",
            "})\n",
            "List of Authors:\n",
            "1. عبد القادر الجزائري\n",
            "2. الهدم بن امرئ القيس\n",
            "3. عبدالله البردوني\n",
            "4. الراضي بالله\n",
            "5. عبد الرحمن بن مساعد\n",
            "6. العباس بن الأحنف\n",
            "7. المثلم الفزاري\n",
            "8. هشام الجخ\n",
            "9. ابن الرعلاء\n",
            "10. يوسف النبهاني\n",
            "11. الوأواء الدمشقي\n",
            "12. محمد ولد ابن ولد أحميدا\n",
            "13. مصطفى صادق الرافعي\n",
            "14. الباخرزي\n",
            "15. حفني ناصف\n",
            "16. حافظ ابراهيم\n",
            "17. الإمام الشافعي\n",
            "18. الجاحظ\n",
            "19. العقار بن سليل\n",
            "20. فهد العسكر\n",
            "21. سهام آل براهمي\n",
            "22. الأصمعي\n",
            "23. زياد السعودي\n",
            "24. ابن دريد الأزدي\n",
            "25. عنترة بن شداد\n",
            "26. بغثر بن لقيط الأسدي\n",
            "27. النابغة الغنوي\n",
            "28. كريم معتوق\n",
            "29. أبو الهدى الصيادي\n",
            "30. الامير منجك باشا\n",
            "31. ابن حيوس\n",
            "32. الشريف الرضي\n",
            "33. إبراهيم اليازجي\n",
            "34. الأبيوردي\n",
            "35. لسان الدين بن الخطيب\n",
            "36. عبد الولي الشميرى\n",
            "37. مدثر بن إبراهيم بن الحجاز\n",
            "38. سليم عبدالقادر\n",
            "39. أم الضحاك المحاربية\n",
            "40. الميكالي\n",
            "41. نسيب عريضة\n",
            "42. عدنان الصائغ\n",
            "43. صردر\n",
            "44. إبراهيم عبد القادر المازني\n",
            "45. محمد المعولي\n",
            "46. أبو الفضل الكناني\n",
            "47. ظافر الحداد\n",
            "48. صخر الغي\n",
            "49. جورج جرداق\n",
            "50. ماء العينين\n",
            "51. الحارث بن حلزة\n",
            "52. جبلة بن الحارث\n",
            "53. ابن المُقري\n",
            "54. الأحنف العكبري\n",
            "55. دريد بن الصمة\n",
            "56. ابن الزقاق\n",
            "57. جابر المرني\n",
            "58. مصطفى التل\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Step 2: Create a dictionary to store poet names and their character counts\n",
        "poet_char_counts = {}\n",
        "\n",
        "for poem in dataset['train']:\n",
        "    poet_name = poem['poet_name']\n",
        "    poem_text = \" \".join(poem['poem_verses'])  # Combine all verses into a single string\n",
        "    char_count = len(poem_text)  # Count the number of characters in the poem\n",
        "\n",
        "    if poet_name in poet_char_counts:\n",
        "        poet_char_counts[poet_name] += char_count\n",
        "    else:\n",
        "        poet_char_counts[poet_name] = char_count\n",
        "\n",
        "sorted_poets = sorted(poet_char_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"List of Poets and Their Character Counts:\")\n",
        "for poet, count in sorted_poets:\n",
        "    print(f\"{poet}: {count} characters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk3UFWvboyKS",
        "outputId": "9bce6a84-c5a0-438d-9ee8-1726528ea53f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of Poets and Their Character Counts:\n",
            "الشريف الرضي: 2375819 characters\n",
            "لسان الدين بن الخطيب: 1289849 characters\n",
            "ابن حيوس: 1129111 characters\n",
            "ابن المُقري: 1108465 characters\n",
            "الأبيوردي: 971938 characters\n",
            "أبو الهدى الصيادي: 941580 characters\n",
            "حافظ ابراهيم: 851437 characters\n",
            "يوسف النبهاني: 700750 characters\n",
            "محمد ولد ابن ولد أحميدا: 586776 characters\n",
            "محمد المعولي: 517804 characters\n",
            "الأحنف العكبري: 514566 characters\n",
            "ظافر الحداد: 472157 characters\n",
            "العباس بن الأحنف: 391126 characters\n",
            "الامير منجك باشا: 362475 characters\n",
            "صردر: 357472 characters\n",
            "إبراهيم اليازجي: 310590 characters\n",
            "حفني ناصف: 293109 characters\n",
            "مصطفى صادق الرافعي: 268746 characters\n",
            "الوأواء الدمشقي: 237757 characters\n",
            "إبراهيم عبد القادر المازني: 228910 characters\n",
            "فهد العسكر: 217127 characters\n",
            "ابن الزقاق: 206973 characters\n",
            "مصطفى التل: 180659 characters\n",
            "ابن دريد الأزدي: 170101 characters\n",
            "الباخرزي: 150728 characters\n",
            "عبد القادر الجزائري: 114250 characters\n",
            "عبد الولي الشميرى: 90303 characters\n",
            "نسيب عريضة: 87882 characters\n",
            "الميكالي: 84196 characters\n",
            "عبدالله البردوني: 76636 characters\n",
            "ماء العينين: 73348 characters\n",
            "الإمام الشافعي: 65252 characters\n",
            "دريد بن الصمة: 59895 characters\n",
            "زياد السعودي: 59038 characters\n",
            "الراضي بالله: 54283 characters\n",
            "عدنان الصائغ: 39968 characters\n",
            "هشام الجخ: 38195 characters\n",
            "عنترة بن شداد: 33055 characters\n",
            "سهام آل براهمي: 29753 characters\n",
            "سليم عبدالقادر: 24229 characters\n",
            "مدثر بن إبراهيم بن الحجاز: 18256 characters\n",
            "صخر الغي: 17116 characters\n",
            "الجاحظ: 16422 characters\n",
            "الحارث بن حلزة: 12366 characters\n",
            "عبد الرحمن بن مساعد: 8812 characters\n",
            "كريم معتوق: 7825 characters\n",
            "جورج جرداق: 7275 characters\n",
            "أبو الفضل الكناني: 4013 characters\n",
            "أم الضحاك المحاربية: 3306 characters\n",
            "جبلة بن الحارث: 3272 characters\n",
            "الأصمعي: 2799 characters\n",
            "بغثر بن لقيط الأسدي: 2118 characters\n",
            "العقار بن سليل: 1866 characters\n",
            "الهدم بن امرئ القيس: 945 characters\n",
            "ابن الرعلاء: 831 characters\n",
            "المثلم الفزاري: 497 characters\n",
            "النابغة الغنوي: 307 characters\n",
            "جابر المرني: 141 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Function to normalize Arabic characters\n",
        "def normalize_arabic(text):\n",
        "    # Remove diacritics (e.g., َ, ً, ُ, etc.)\n",
        "    text = re.sub(r\"[\\u064B-\\u065F\\u0670\\u06D6-\\u06ED]\", \"\", text)\n",
        "\n",
        "    # Normalize common variations\n",
        "    text = text.replace(\"أ\", \"ا\").replace(\"إ\", \"ا\").replace(\"آ\", \"ا\")  # Normalize alef\n",
        "    text = text.replace(\"ى\", \"ي\")  # Normalize alef maqsura to ya\n",
        "    text = text.replace(\"ؤ\", \"و\").replace(\"ئ\", \"ي\")  # Normalize hamza-related letters\n",
        "    text = text.replace(\"ة\", \"ه\")  # Normalize ta marbuta to ha\n",
        "    return text\n",
        "\n",
        "poet_name = \"ابن المُقري\"\n",
        "\n",
        "filtered_poems = [poem for poem in dataset['train'] if poem['poet_name'] == poet_name]\n",
        "\n",
        "if not filtered_poems:\n",
        "    print(f\"No poems found for the poet: {poet_name}\")\n",
        "else:\n",
        "    combined_text = \"\\n\\n\".join(\n",
        "        normalize_arabic(\n",
        "            \"\".join(word.strip(\"[],\") for word in poem['poem_verses'])\n",
        "        )\n",
        "        for poem in filtered_poems\n",
        "    )\n",
        "\n",
        "    print(combined_text[:2000])\n",
        "\n",
        "    with open(\"combined_normalized_poems.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(combined_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvlg8cdKmQFq",
        "outputId": "17c8ed6a-9aaa-4f4c-ff4a-7b45d527fbbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'رضاك عني رضا الباري به قرنا' 'فمن يضعه ولو اعطي المني غبنا' 'استغفر الله من ذنب اتيت به' 'غضبت منه وقول لم يكن حسنا' 'عضضت كفي حتي كدت اكلها' 'مما ندمت وذابت مهجتي حزنا' 'يا منعما لا اوفي شكره ابدا' 'لو ابذل النفس مرضاته ثمنا' 'هيهات ما ولد موف لوالده' 'معشار ما قلدته كفه مننا' 'هلكت ان لم اكن كالعهد يشملني' 'رضاك عني وهل لي من رضاك غنا' 'ما انت والله في حقي بمتهم' 'ولا ملوم ولكن الملوم انا' 'كم نعمه لك مثل الطوق في عنقي' 'وكم يد لك بيضا في يدي ومنا' 'شلت يدي حين اتي الامر تكرهه' 'وحين اصغي لما لا تشتهي اذنا' 'اعرضت عني فقام الدهر يرشقني' 'بصرف احداثه من ها هنا وهنا' 'وهنت عند رجال لا خلاق لهم' 'فمن اناديه لوي راسه وثني' 'اعراض وجهك عني قد لقيت به' 'امرا اغبطت له في الترب من دفنا' 'قد كنت اشفق بي مني فيا اسفا' 'علي مكانتي الاولي ويا حزنا' 'اذا شكار ضرا من زمانهم' 'فحالتي تلك لا اشكو لها الزمنا' 'واليوم اصبحت مما انت تسعدني' 'مستصغرا في عيون الناس ممتهنا' 'وانت جاهي اذا هملتني انهدمت' 'قواعد كنت قد اسستها وبنا' 'هجرت غيرك خوفا ان يقول فتي' 'ما كان ذا لابيه هل يكون لنا' 'وما كمثلك في ابايهم احد' 'ابر بابن واحلي مكسرا وجني' 'ما عذر مثلي اذا ما شاع بينهم' 'هذا الجفاء وقد ظنوا بي الظننا' 'وهل يليق بمثلي ان يقال اتي' 'وما ليس يرضي ابوه او يقال خنا' 'والله والله لو قطعتني قطعا' 'ما ازددت الا ودادا خالصا وثنا' 'وما اجازيك لو اني اطعتك في' 'امر تفارق روحي عنده البدنا' 'اذا ذكرتك غضبانا وضعت يدي' 'علي فواد وها حزنا وذاب ضني' 'وهمت لولا اياد قد سبقن اذا' 'ذكرتها وفوادي طاير سكنا' 'امسي سمير نجوم الافق لا كبدي' 'يطفي ولا جفن عيني يعرف الوسنا' 'فمن سواه تراه اخذ بيدي' 'ومن سواك اذا رمت الحنو حنا' 'متي ارجي صنيعا من سواك اكن' 'كمن يرجي بثدييي حامل لبنا' 'وقد اتيت وامالي تبشرني' 'بالخير عنك وقد اظهرت ما بطنا' 'قصدي رضاك فان تظفر يداي به' 'فما ابالي بمن يرضي ومن حزنا' 'فاسلم ودم ما دجي ليل ولاح ضيا' 'يفديك اكبرنا سنا واصغرنا'\n",
            "\n",
            "'الا يا ايها المحبوب لم لا' 'وصلت من الرجا لك منه داب' 'اطعت الدهر في فلا ابالي' 'اذا ما انت لي والدهر حزب' 'فديتك انت ارفق بي فاني' 'وان دهري ابان جفا محب' 'فيا والي عذابي كنت اولي' 'بعفوك اذ قدرت وليس ذنب' 'يلوم علي انتوالي الحب من لا' 'يعد مع الرجال لديه \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hrz-WURmtuCb",
        "outputId": "82c4b55a-136a-497b-afdb-b13099cac225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78bca852c850>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "block_size = 256\n",
        "max_iters = 5000\n",
        "eval_interval = 300\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 384\n",
        "n_head = 6\n",
        "n_layer = 6\n",
        "dropout = 0.2\n"
      ],
      "metadata": {
        "id": "aOKO1w5-BE_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('input.txt', 'r',encoding='utf-8') as f:\n",
        "#   text = f.read()"
      ],
      "metadata": {
        "id": "uC4XYY63X8yX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = combined_text"
      ],
      "metadata": {
        "id": "Q4QxA8P7rPZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlWsdJF-YM7-",
        "outputId": "ea9bca0e-fc86-4a3d-96e3-b334fbce8564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "524346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ac0EgqEYQtg",
        "outputId": "d4a2ec41-e54d-48a4-b83f-27a1fcfbd3c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'رضاك عني رضا الباري به قرنا' 'فمن يضعه ولو اعطي المني غبنا' 'استغفر الله من ذنب اتيت به' 'غضبت منه وقول لم يكن حسنا' 'عضضت كفي حتي كدت اكلها' 'مما ندمت وذابت مهجتي حزنا' 'يا منعما لا اوفي شكره ابدا' 'لو ابذل النفس مرضاته ثمنا' 'هيهات ما ولد موف لوالده' 'معشار ما قلدته كفه مننا' 'هلكت ان لم اكن كالعهد يشملني' 'رضاك عني وهل لي من رضاك غنا' 'ما انت والله في حقي بمتهم' 'ولا ملوم ولكن الملوم انا' 'كم نعمه لك مثل الطوق في عنقي' 'وكم يد لك بيضا في يدي ومنا' 'شلت يدي حين اتي الامر تكرهه' 'وحين اصغي لما لا تشتهي اذنا' 'اعرضت عني فقام الدهر يرشقني' 'بصرف احداثه من ها هنا وهنا' 'وهنت عند رجال لا خلاق لهم' 'فمن اناديه لوي راسه وثني' 'اعراض وجهك عني قد لقيت به' 'امرا اغبطت له في الترب من دفنا' 'قد كنت اشفق بي مني فيا اسفا' 'علي مكانتي الاولي ويا حزنا' 'اذا شكار ضرا من زمانهم' 'فحالتي تلك لا اشكو لها الزمنا' 'واليوم اصبحت مما انت تسعدني' 'مستصغرا في عيون الناس ممتهنا' 'وانت جاهي اذا هملتني انهدمت' 'قواعد كنت قد اسستها وبنا' 'هجرت غيرك خوفا ان يقول فتي' 'ما كان ذا لابيه هل يكون لنا' 'وما كمثلك في اب\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-2iYP-CYThP",
        "outputId": "8def50ec-150a-4f02-bc5a-dadaf718576e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 'ءابتثجحخدذرزسشصضطظعغفقكلمنهوي\n",
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "print(encode(\"بلال\"))\n",
        "print(decode(encode(\"بلال\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC5PLMtuYojS",
        "outputId": "f7f19d49-b374-4f13-ccff-5cdc844c9e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 26, 4, 26]\n",
            "بلال\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape,data.dtype)\n",
        "print(data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BJKDYu6Zj7X",
        "outputId": "14be8f7b-05bd-4cb1-c51a-bec69a3e47f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([524346]) torch.int64\n",
            "tensor([ 2, 13, 18,  4, 25,  1, 21, 28, 31,  1, 13, 18,  4,  1,  4, 26,  5,  4,\n",
            "        13, 31,  1,  5, 29,  1, 24, 13, 28,  4,  2,  1,  2, 23, 27, 28,  1, 31,\n",
            "        18, 21, 29,  1, 30, 26, 30,  1,  4, 21, 19, 31,  1,  4, 26, 27, 28, 31,\n",
            "         1, 22,  5, 28,  4,  2,  1,  2,  4, 15,  6, 22, 23, 13,  1,  4, 26, 26,\n",
            "        29,  1, 27, 28,  1, 12, 28,  5,  1,  4,  6, 31,  6,  1,  5, 29,  2,  1,\n",
            "         2, 22, 18,  5,  6,  1, 27, 28, 29,  1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "UwSd3Du8gtRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size] # [0,1,2,3,4]\n",
        "y = train_data[1:block_size+1] # [1,2,3,4,5] shifted ->\n",
        "for t in range(block_size):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(f\"when input is {context} target is {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC_8vHHrmRwZ",
        "outputId": "6177f756-95f6-4701-f0a8-cf21a264018e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([18]) target is 47\n",
            "when input is tensor([18, 47]) target is 56\n",
            "when input is tensor([18, 47, 56]) target is 57\n",
            "when input is tensor([18, 47, 56, 57]) target is 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) target is 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) target is 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) target is 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) target is 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "\n",
        "#batch_size = 4\n",
        "#block_size = 8\n",
        "\n",
        "def get_batch(split):\n",
        "  data = train_data if split == 'train' else val_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  x,y = x.to(device), y.to(device)\n",
        "  return x,y\n",
        "\n",
        "xb,yb = get_batch('train')\n",
        "# print('inputs:')\n",
        "# print(xb.shape)\n",
        "# print(xb)\n",
        "# print('targets:')\n",
        "# print(yb.shape)\n",
        "# print(yb)\n",
        "\n",
        "# print('----')\n",
        "\n",
        "\n",
        "# for b in range(batch_size):\n",
        "#   for t in range(block_size):\n",
        "#     context = xb[b,:t+1]\n",
        "#     target = yb[b,t]\n",
        "#     print(f\"when input is {context.tolist()} target is {target}\")"
      ],
      "metadata": {
        "id": "-T01Vs7PoFrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  out = {}\n",
        "  m.eval()\n",
        "  for split in ['train','val']:\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      X,Y = get_batch(split)\n",
        "      logits,loss = m(X,Y)\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "  m.train()\n",
        "  return out"
      ],
      "metadata": {
        "id": "qGxia-KyB7v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Feedforward(nn.Module):\n",
        "  def __init__(self,n_embd):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(n_embd,4 * n_embd),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4 * n_embd,n_embd)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "11XJ8KWZZ00t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,n_embd,n_head):\n",
        "    super().__init__()\n",
        "    head_size = n_embd // n_head\n",
        "    self.sa_head = MultiHeadAttention(n_head,head_size)\n",
        "    self.ffwd = Feedforward(n_embd)\n",
        "    self.ln1 = nn.LayerNorm(n_embd)\n",
        "    self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x + self.sa_head(self.ln1(x))\n",
        "    x = x + self.ffwd(self.ln2(x))\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "2TjXzjv2dJEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PicoGPT(nn.Module):\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "    self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "    #self.blocks = nn.Sequential(*[Decoder(n_embd,4),Decoder(n_embd,4),Decoder(n_embd,4),nn.LayerNorm(n_embd))\n",
        "    self.blocks = nn.Sequential(*[Decoder(n_embd,n_head=n_head) for _ in range(n_layer)])\n",
        "    self.ln_f = nn.LayerNorm(n_embd)\n",
        "    self.ffwd = Feedforward(n_embd)\n",
        "    self.lm_head = nn.Linear(n_embd,vocab_size)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "    B ,T = idx.shape\n",
        "    tok_emb = self.token_embedding_table(idx) # (B,T,C) each charachter has (Vocab size) outputs\n",
        "    pos_emb = self.position_embedding_table(torch.arange(T,device=device)) # (T,C) (STUPID POSITIONAL ENCODING)\n",
        "    x = tok_emb + pos_emb\n",
        "    x = self.blocks(x)\n",
        "    logits = self.lm_head(x)\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B , T , C  = logits.shape\n",
        "      logits = logits.view(B*T,C) # collapsing B T\n",
        "      #print(\"hh\",targets.shape)\n",
        "      targets = targets.view(B*T)\n",
        "      loss = F.cross_entropy(logits,targets) # (B,C,T)\n",
        "\n",
        "    return logits,loss\n",
        "  def generate(self,idx,max_new_tokens):\n",
        "    for _ in range(max_new_tokens):\n",
        "      idx_crop = idx[:,-block_size:]\n",
        "      logits,loss = self(idx_crop)\n",
        "      logits = logits[:,-1,:]\n",
        "      probs = F.softmax(logits,dim=-1)\n",
        "      idx_next = torch.multinomial(probs,num_samples=1)\n",
        "      idx = torch.cat((idx,idx_next),dim=1)\n",
        "    return idx\n",
        "\n",
        "\n",
        "#print(xb)\n",
        "#print(yb)\n",
        "\n",
        "#print(decode(m.generate(idx,max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "id": "Ke-ZeVXVrhRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "  def __init__(self,head_size):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(n_embd,head_size,bias=False)\n",
        "    self.query = nn.Linear(n_embd,head_size,bias=False)\n",
        "    self.value = nn.Linear(n_embd,head_size,bias=False)\n",
        "    self.register_buffer('tril',torch.tril(torch.ones(block_size,block_size)))\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,x):\n",
        "    B,T,C = x.shape\n",
        "    k = self.key(x)\n",
        "    q = self.query(x)\n",
        "    wei = q @ k.transpose(-2,-1) * C**-0.5\n",
        "    wei = wei.masked_fill(self.tril[:T,:T] == 0,float('-inf'))\n",
        "    wei = F.softmax(wei,dim=-1)\n",
        "    wei = self.dropout(wei)\n",
        "    v = self.value(x)\n",
        "    out = wei @ v\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "getSCb-bOpj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,num_heads,head_size):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "    self.proj = nn.Linear(n_embd,n_embd)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = torch.cat([h(x) for h in self.heads],dim=-1)\n",
        "    out = self.dropout(self.proj(out))\n",
        "    return out"
      ],
      "metadata": {
        "id": "bYRUpSIkWWoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer = torch.optim.AdamW(m.parameters(),lr=1e-4)"
      ],
      "metadata": {
        "id": "vgEyd6jz23ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for steps in range(10000):\n",
        "#   xb, yb = get_batch('train')\n",
        "\n",
        "#   logits,loss = m(xb,yb)\n",
        "#   optimizer.zero_grad(set_to_none=True)\n",
        "#   loss.backward()\n",
        "#   optimizer.step()\n",
        "# print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVPePIXc3H1z",
        "outputId": "563064b5-a26d-4e36-dd5c-a86bc5d7554c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.6591148376464844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = PicoGPT(vocab_size)\n",
        "m = m.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step: {iter}: train loss: {losses['train']:.4f}, val loss: {losses['val']:.4f}\")\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiA5OH8DByVd",
        "outputId": "f0982fe3-7081-492a-a764-c9653741b895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0: train loss: 3.8686, val loss: 3.8686\n",
            "step: 300: train loss: 2.4765, val loss: 2.4648\n",
            "step: 600: train loss: 2.1881, val loss: 2.1873\n",
            "step: 900: train loss: 2.0633, val loss: 2.0653\n",
            "step: 1200: train loss: 1.9602, val loss: 1.9689\n",
            "step: 1500: train loss: 1.8844, val loss: 1.9079\n",
            "step: 1800: train loss: 1.8187, val loss: 1.8608\n",
            "step: 2100: train loss: 1.7736, val loss: 1.8294\n",
            "step: 2400: train loss: 1.7282, val loss: 1.8079\n",
            "step: 2700: train loss: 1.6864, val loss: 1.7918\n",
            "step: 3000: train loss: 1.6495, val loss: 1.7829\n",
            "step: 3300: train loss: 1.6087, val loss: 1.7707\n",
            "step: 3600: train loss: 1.5640, val loss: 1.7734\n",
            "step: 3900: train loss: 1.5223, val loss: 1.7816\n",
            "step: 4200: train loss: 1.4786, val loss: 1.7927\n",
            "step: 4500: train loss: 1.4298, val loss: 1.8068\n",
            "step: 4800: train loss: 1.3729, val loss: 1.8147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = torch.zeros((1,1),dtype=torch.long,device=device)\n",
        "print(context.shape)\n",
        "print(decode(m.generate(context,max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QB3nkbu-oh0",
        "outputId": "129009f9-1971-4aec-fc24-42b95afb9dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1])\n",
            "\n",
            "كم في الاعار شديد' 'حسبي الي السن ان تبتن' 'ظهرت الفرجاء لا يخفي بخلي' 'اخو باق العجا منه الخير' 'يجود البحر اليوم بسير الردي' 'فيا للفقطات اخسر المعود' 'للابحر الابن الليالي كعوده' 'للصاهد الابحر والهم بالدعا' 'الري انه عهد كانت بيض' 'واخجل يستغضي فالهوي العجاذل' 'لي عطش فخر ذي والمنطق حاجه' 'وفاعات كل ارض لي حق له' 'فعلت مكانات عليه تسكينها' 'لما تلم منه المدح في الاخمر' 'لا زاجتها بملك توم ركيبه' 'فوزت بسم لكي وعقوق عيونه' 'لم تهوي الليل عنك خريقه التمايه' 'من لا يريك بقاء رد العيونه' 'كذب يح\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2\n",
        "x = torch.randn(B,T,C)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1yq6fZxA7M8",
        "outputId": "77b694ca-1657-4ea0-d1e0-b6fb408e03f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "    xprev = x[b,:t+1]\n",
        "    xbow[b,t] = torch.mean(xprev,0)"
      ],
      "metadata": {
        "id": "yBjraLglB7xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wei = torch.tril(torch.ones(T,T))\n",
        "wei = wei / wei.sum(1,keepdim=True)\n",
        "xbow2 = wei @ x\n",
        "\n",
        "torch.allclose(xbow,xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oaqwCmqQoX5",
        "outputId": "5df2520e-6c88-4b21-ba4d-cadcf3ad3d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "B,T,C =  4,8,32\n",
        "x = torch.randn(B,T,C)\n",
        "head_size = 16\n",
        "key = nn.Linear(C,head_size,bias=False)\n",
        "query = nn.Linear(C,head_size,bias=False)\n",
        "value = nn.Linear(C,head_size,bias=False)\n",
        "k = key(x) # B T 16\n",
        "q = query(x) # B T 16\n",
        "wei = q @ k.transpose(-2,-1) # B T 16 @ B 16 T --> B T T\n",
        "\n",
        "tril = torch.tril(torch.ones(T,T))\n",
        "#wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril==0,float('-inf'))\n",
        "wei = F.softmax(wei,dim=-1)\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54_mo2M8StSS",
        "outputId": "95b60575-cb13-400b-829a-3cde6cfef63b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaCXy8i4JrnA",
        "outputId": "fd720f93-787a-4709-a694-30f8f8eb921c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
              "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
              "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOKgNjSQKZ_c",
        "outputId": "23f394b6-10ea-4a88-8381-ea1538e599f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.0894, -0.4926],\n",
              "        [ 0.1490, -0.3199],\n",
              "        [ 0.3504, -0.2238],\n",
              "        [ 0.3525,  0.0545],\n",
              "        [ 0.0688, -0.0396],\n",
              "        [ 0.0927, -0.0682],\n",
              "        [-0.0341,  0.1332]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.ones(3,3)\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-OhsT79PIkE",
        "outputId": "1903547b-6b8f-44ea-dd15-2ce026034346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[14., 16.],\n",
            "        [14., 16.],\n",
            "        [14., 16.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(m.state_dict(), 'picogpt_weights.pth')\n",
        "\n"
      ],
      "metadata": {
        "id": "ZwHnU2VGWSV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inference"
      ],
      "metadata": {
        "id": "BVMjikenWe88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First recreate the model architecture\n",
        "model = PicoGPT(vocab_size=32)  # Use the same vocab_size as during training\n",
        "\n",
        "# Load the saved weights\n",
        "model.load_state_dict(torch.load('picogpt_weights.pth'))\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZywFjZ9XWeTQ",
        "outputId": "9d88ac2e-3d96-42ea-d3c9-b5fee779e462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-41eed76683c1>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('picogpt_weights.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PicoGPT(\n",
              "  (token_embedding_table): Embedding(32, 384)\n",
              "  (position_embedding_table): Embedding(256, 384)\n",
              "  (blocks): Sequential(\n",
              "    (0): Decoder(\n",
              "      (sa_head): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): Feedforward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): Decoder(\n",
              "      (sa_head): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): Feedforward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (2): Decoder(\n",
              "      (sa_head): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): Feedforward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (3): Decoder(\n",
              "      (sa_head): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): Feedforward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (4): Decoder(\n",
              "      (sa_head): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): Feedforward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (5): Decoder(\n",
              "      (sa_head): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): Feedforward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "  (ffwd): Feedforward(\n",
              "    (net): Sequential(\n",
              "      (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=384, out_features=32, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_token, max_new_tokens=100):\n",
        "    # Convert starting token to tensor\n",
        "    idx = torch.tensor([[start_token]], dtype=torch.long, device=device)\n",
        "\n",
        "    # Generate text\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_new_tokens):\n",
        "            # Get predictions\n",
        "            logits, _ = model(idx)\n",
        "\n",
        "            # Focus on last time step\n",
        "            logits = logits[:, -1, :]  # (B, C)\n",
        "\n",
        "            # Get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "            # Sample from distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "            # Append to sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "# Example usage\n",
        "start_token = 0  # Your starting token index\n",
        "generated_sequence = generate_text(model, start_token, max_new_tokens=100)\n",
        "print(decode(generated_sequence[0].tolist()))  # Assuming you have a decode function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrNUGbA4W3xL",
        "outputId": "ca35d5b3-ebd1-4041-b462-3c6799b657de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'تممعنا عن قدما لباقيك العدي' 'متي يذيق الاعدا علي الشرك' 'فقمت واي عليك وكل ينظر'\n",
            "\n",
            "'لقد احل طود بسي\n"
          ]
        }
      ]
    }
  ]
}